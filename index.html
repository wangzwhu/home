<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="assets/css/bootstrap.min.css">
    <title>Zheng Wang's Homepage</title>
    <style>
        .indented {
            text-indent: 2em; /* 缩进2个字符 */
            line-height: 0.1; /* 设置行高，提升可读性 */
        }
    </style>
  </head>
  
  <body>  
    <div class="container" style="max-width: 1600px;">

	<div class="row mt-3 mb-3">
		<div class="col-sm-2">
			<img src="img/wangz2.jpg" class="img-fluid rounded-lg" alt="Responsive image">
		</div>
		
		<div class="col-sm-10">
			<div class="row">
				<div class="col-sm-10">
					<h2>Zheng Wang (王正)</h2>
					<h6>Professor, National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University</h5>
					<h6>Director, Computer Experimental Teaching Centre, School of Computer Science, Wuhan University</h5>
				</div>
			</div>
			<br>
				<div class="d-flex flex-row">
					<div class="pr-3">
						<svg width="1em" height="1em" viewBox="0 0 16 16" class="bi bi-house-door-fill" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
						<path d="M6.5 10.995V14.5a.5.5 0 0 1-.5.5H2a.5.5 0 0 1-.5-.5v-7a.5.5 0 0 1 .146-.354l6-6a.5.5 0 0 1 .708 0l6 6a.5.5 0 0 1 .146.354v7a.5.5 0 0 1-.5.5h-4a.5.5 0 0 1-.5-.5V11c0-.25-.25-.5-.5-.5H7c-.25 0-.5.25-.5.495z"/>
						<path fill-rule="evenodd" d="M13 2.5V6l-2-2V2.5a.5.5 0 0 1 .5-.5h1a.5.5 0 0 1 .5.5z"/>
						</svg>
					</div>
					<div>Room South-602, Undergraduate School Building, Wuhan University, Wuhan 430072, China</div>
				</div>

				<div class="row">
					<div class="col-sm-4">
						<div class="d-flex flex-row">
							<div class="pr-3">
							<svg width="1em" height="1em" viewBox="0 0 16 16" class="bi bi-envelope-fill" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
							<path fill-rule="evenodd" d="M.05 3.555A2 2 0 0 1 2 2h12a2 2 0 0 1 1.95 1.555L8 8.414.05 3.555zM0 4.697v7.104l5.803-3.558L0 4.697zM6.761 8.83l-6.57 4.027A2 2 0 0 0 2 14h12a2 2 0 0 0 1.808-1.144l-6.57-4.027L8 9.586l-1.239-.757zm3.436-.586L16 11.801V4.697l-5.803 3.546z"/></svg>
							</div>
						<div>wangzwhu(at)whu.edu.cn; wangzwhu(at)gmail.com</div>
						</div>
					</div>				
				</div>
			<br>
			<p>
    In 2017, I received my Ph.D. from the 
    <a href="http://multimedia.whu.edu/">National Engineering Research Center for Multimedia Software (国家多媒体软件工程技术研究中心)</a>, 
    <a href="https://www.whu.edu.cn/">Wuhan University (武汉大学)</a>. 
    From 2017 to 2020, I worked as a JST CREST Project Researcher (特任研究員) and JSPS Fellowship Researcher (日本学術振興会外国人特別研究員) at the 
    <a href="https://www.nii.ac.jp/en/">National Institute of Informatics (国立情報学研究所)</a>, Japan, under the guidance of 
    <a href="http://www.satoh-lab.nii.ac.jp/index.html">Shin'ichi Satoh</a>. 
    From 2020 to 2021, I served as an Assistant Professor at 
    <a href="https://www.u-tokyo.ac.jp/en/">The University of Tokyo (東京大学)</a>, where I collaborated with 
    <a href="https://www.cvm.t.u-tokyo.ac.jp/en/">Toshihiko Yamasaki</a> and 
    <a href="https://www.hal.t.u-tokyo.ac.jp/lab/en/">Kiyoharu Aizawa</a>.
    I have also participated in several international research visits, including:
    <a href="https://www.a-star.edu.sg/">A*STAR</a>, Singapore, in 2023, working with 
    <a href="https://hongyuanzhu.github.io/">Hongyuan Zhu</a> and 
    <a href="https://www.a-star.edu.sg/cfar/about-cfar/management/prof-ong-yew-soon">Ong Yew Soon</a>; 
    <a href="https://www.nextcenter.org/">NExT++, National University of Singapore (NUS)</a> in 2024, collaborating with 
    <a href="https://www.chuatatseng.com/">Tat-Seng Chua</a>; and 
    <a href="https://ai.nus.edu.sg/">NAII, NUS</a>, in 2025, working with 
    <a href="https://www.comp.nus.edu.sg/~mohan/">Mohan Kankanhalli</a>.
</p>
	</div> 	
</div>

 <div>	   
      <h5>
 <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-person-workspace" viewBox="0 0 16 16"><path d="M4 16s-1 0-1-1 1-4 5-4 5 3 5 4-1 1-1 1zm4-5.95a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5"/><path d="M2 1a2 2 0 0 0-2 2v9.5A1.5 1.5 0 0 0 1.5 14h.653a5.4 5.4 0 0 1 1.066-2H1V3a1 1 0 0 1 1-1h12a1 1 0 0 1 1 1v9h-2.219c.554.654.89 1.373 1.066 2h.653a1.5 1.5 0 0 0 1.5-1.5V3a2 2 0 0 0-2-2z"/></svg>
	      <a href="http://aim-nercms.whu.edu.cn/">AIM Lab</a> | 
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-people-fill" viewBox="0 0 16 16"><path d="M7 14s-1 0-1-1 1-4 5-4 5 3 5 4-1 1-1 1zm4-6a3 3 0 1 0 0-6 3 3 0 0 0 0 6m-5.784 6A2.24 2.24 0 0 1 5 13c0-1.355.68-2.75 1.936-3.72A6.3 6.3 0 0 0 5 9c-4 0-5 3-5 4s1 1 1 1zM4.5 8a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5"/></svg>
	      <a href="member.html">My Group</a> | 
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-rocket" viewBox="0 0 16 16">  <path d="M8 8c.828 0 1.5-.895 1.5-2S8.828 4 8 4s-1.5.895-1.5 2S7.172 8 8 8"/><path d="M11.953 8.81c-.195-3.388-.968-5.507-1.777-6.819C9.707 1.233 9.23.751 8.857.454a3.5 3.5 0 0 0-.463-.315A2 2 0 0 0 8.25.064.55.55 0 0 0 8 0a.55.55 0 0 0-.266.073 2 2 0 0 0-.142.08 4 4 0 0 0-.459.33c-.37.308-.844.803-1.31 1.57-.805 1.322-1.577 3.433-1.774 6.756l-1.497 1.826-.004.005A2.5 2.5 0 0 0 2 12.202V15.5a.5.5 0 0 0 .9.3l1.125-1.5c.166-.222.42-.4.752-.57.214-.108.414-.192.625-.281l.198-.084c.7.428 1.55.635 2.4.635s1.7-.207 2.4-.635q.1.044.196.083c.213.09.413.174.627.282.332.17.586.348.752.57l1.125 1.5a.5.5 0 0 0 .9-.3v-3.298a2.5 2.5 0 0 0-.548-1.562zM12 10.445v.055c0 .866-.284 1.585-.75 2.14.146.064.292.13.425.199.39.197.8.46 1.1.86L13 14v-1.798a1.5 1.5 0 0 0-.327-.935zM4.75 12.64C4.284 12.085 4 11.366 4 10.5v-.054l-.673.82a1.5 1.5 0 0 0-.327.936V14l.225-.3c.3-.4.71-.664 1.1-.861.133-.068.279-.135.425-.199M8.009 1.073q.096.06.226.163c.284.226.683.621 1.09 1.28C10.137 3.836 11 6.237 11 10.5c0 .858-.374 1.48-.943 1.893C9.517 12.786 8.781 13 8 13s-1.517-.214-2.057-.607C5.373 11.979 5 11.358 5 10.5c0-4.182.86-6.586 1.677-7.928.409-.67.81-1.082 1.096-1.32q.136-.113.236-.18Z"/><path d="M9.479 14.361c-.48.093-.98.139-1.479.139s-.999-.046-1.479-.139L7.6 15.8a.5.5 0 0 0 .8 0z"/></svg>
	      <a href="research.html">Research Topics</a> | 
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-google" viewBox="0 0 16 16"><path d="M15.545 6.558a9.4 9.4 0 0 1 .139 1.626c0 2.434-.87 4.492-2.384 5.885h.002C11.978 15.292 10.158 16 8 16A8 8 0 1 1 8 0a7.7 7.7 0 0 1 5.352 2.082l-2.284 2.284A4.35 4.35 0 0 0 8 3.166c-2.087 0-3.86 1.408-4.492 3.304a4.8 4.8 0 0 0 0 3.063h.003c.635 1.893 2.405 3.301 4.492 3.301 1.078 0 2.004-.276 2.722-.764h-.003a3.7 3.7 0 0 0 1.599-2.431H8v-3.08z"/></svg>
	      <a href="https://scholar.google.com/citations?user=-WHTbpUAAAAJ">Google scholar</a> | 
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-database" viewBox="0 0 16 16"><path d="M4.318 2.687C5.234 2.271 6.536 2 8 2s2.766.27 3.682.687C12.644 3.125 13 3.627 13 4c0 .374-.356.875-1.318 1.313C10.766 5.729 9.464 6 8 6s-2.766-.27-3.682-.687C3.356 4.875 3 4.373 3 4c0-.374.356-.875 1.318-1.313M13 5.698V7c0 .374-.356.875-1.318 1.313C10.766 8.729 9.464 9 8 9s-2.766-.27-3.682-.687C3.356 7.875 3 7.373 3 7V5.698c.271.202.58.378.904.525C4.978 6.711 6.427 7 8 7s3.022-.289 4.096-.777A5 5 0 0 0 13 5.698M14 4c0-1.007-.875-1.755-1.904-2.223C11.022 1.289 9.573 1 8 1s-3.022.289-4.096.777C2.875 2.245 2 2.993 2 4v9c0 1.007.875 1.755 1.904 2.223C4.978 15.71 6.427 16 8 16s3.022-.289 4.096-.777C13.125 14.755 14 14.007 14 13zm-1 4.698V10c0 .374-.356.875-1.318 1.313C10.766 11.729 9.464 12 8 12s-2.766-.27-3.682-.687C3.356 10.875 3 10.373 3 10V8.698c.271.202.58.378.904.525C4.978 9.71 6.427 10 8 10s3.022-.289 4.096-.777A5 5 0 0 0 13 8.698m0 3V13c0 .374-.356.875-1.318 1.313C10.766 14.729 9.464 15 8 15s-2.766-.27-3.682-.687C3.356 13.875 3 13.373 3 13v-1.302c.271.202.58.378.904.525C4.978 12.71 6.427 13 8 13s3.022-.289 4.096-.777c.324-.147.633-.323.904-.525"/></svg>
	      <a href="https://dblp.org/pid/w/ZhengWang7.html">DBLP</a> | 
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-person-vcard" viewBox="0 0 16 16"><path d="M5 8a2 2 0 1 0 0-4 2 2 0 0 0 0 4m4-2.5a.5.5 0 0 1 .5-.5h4a.5.5 0 0 1 0 1h-4a.5.5 0 0 1-.5-.5M9 8a.5.5 0 0 1 .5-.5h4a.5.5 0 0 1 0 1h-4A.5.5 0 0 1 9 8m1 2.5a.5.5 0 0 1 .5-.5h3a.5.5 0 0 1 0 1h-3a.5.5 0 0 1-.5-.5"/><path d="M2 2a2 2 0 0 0-2 2v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2zM1 4a1 1 0 0 1 1-1h12a1 1 0 0 1 1 1v8a1 1 0 0 1-1 1H8.96q.04-.245.04-.5C9 10.567 7.21 9 5 9c-2.086 0-3.8 1.398-3.984 3.181A1 1 0 0 1 1 12z"/></svg>
	      <a href="bio-chinese.html">Bio (Chinese)</a>				
      </h5>
</div>	  

<br>
<br>
	    
<div>

	<div class="row">
		<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-file-earmark-pdf" viewBox="0 0 16 16">
  <path d="M14 14V4.5L9.5 0H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h8a2 2 0 0 0 2-2M9.5 3A1.5 1.5 0 0 0 11 4.5h2V14a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1V2a1 1 0 0 1 1-1h5.5z"/>
  <path d="M4.603 14.087a.8.8 0 0 1-.438-.42c-.195-.388-.13-.776.08-1.102.198-.307.526-.568.897-.787a7.7 7.7 0 0 1 1.482-.645 20 20 0 0 0 1.062-2.227 7.3 7.3 0 0 1-.43-1.295c-.086-.4-.119-.796-.046-1.136.075-.354.274-.672.65-.823.192-.077.4-.12.602-.077a.7.7 0 0 1 .477.365c.088.164.12.356.127.538.007.188-.012.396-.047.614-.084.51-.27 1.134-.52 1.794a11 11 0 0 0 .98 1.686 5.8 5.8 0 0 1 1.334.05c.364.066.734.195.96.465.12.144.193.32.2.518.007.192-.047.382-.138.563a1.04 1.04 0 0 1-.354.416.86.86 0 0 1-.51.138c-.331-.014-.654-.196-.933-.417a5.7 5.7 0 0 1-.911-.95 11.7 11.7 0 0 0-1.997.406 11.3 11.3 0 0 1-1.02 1.51c-.292.35-.609.656-.927.787a.8.8 0 0 1-.58.029m1.379-1.901q-.25.115-.459.238c-.328.194-.541.383-.647.547-.094.145-.096.25-.04.361q.016.032.026.044l.035-.012c.137-.056.355-.235.635-.572a8 8 0 0 0 .45-.606m1.64-1.33a13 13 0 0 1 1.01-.193 12 12 0 0 1-.51-.858 21 21 0 0 1-.5 1.05zm2.446.45q.226.245.435.41c.24.19.407.253.498.256a.1.1 0 0 0 .07-.015.3.3 0 0 0 .094-.125.44.44 0 0 0 .059-.2.1.1 0 0 0-.026-.063c-.052-.062-.2-.152-.518-.209a4 4 0 0 0-.612-.053zM8.078 7.8a7 7 0 0 0 .2-.828q.046-.282.038-.465a.6.6 0 0 0-.032-.198.5.5 0 0 0-.145.04c-.087.035-.158.106-.196.283-.04.192-.03.469.046.822q.036.167.09.346z"/></svg>
		<h5><strong>Selected Publications</strong> (<a href="https://scholar.google.com/citations?user=-WHTbpUAAAAJ">Google scholar</a>)</h5>
	</div>

	<div>
	<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-short" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M4 8a.5.5 0 0 1 .5-.5h5.793L8.146 5.354a.5.5 0 1 1 .708-.708l3 3a.5.5 0 0 1 0 .708l-3 3a.5.5 0 0 1-.708-.708L10.293 8.5H4.5A.5.5 0 0 1 4 8"/>
</svg>Multimedia Content Analysis
	<p class="indented"><a href="https://ieeexplore.ieee.org/abstract/document/10177211">CycMuNet+: Cycle-Projected Mutual Learning for Spatial-Temporal Video Super-Resolution</a>, 
		M Hu, K Jiang, <strong>Z Wang*</strong>, X Bai, R Hu,
 		<em><strong>IEEE TPAMI</strong></em>, 2023</p>
	<p class="indented"><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Both_Style_and_Fog_Matter_Cumulative_Domain_Adaptation_for_Semantic_CVPR_2022_paper.pdf">Both Style and Fog Matter: Cumulative Domain Adaptation for Semantic Foggy Scene Understanding</a>, 
 		X Ma, Z Wang, Y Zhan, Y Zheng, <strong>Z Wang*</strong>, D Dai, CW Lin,
 		<em><strong>CVPR</strong></em>, 2022</p>
	<p class="indented"><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Ma_HumanNeRF-SE_A_Simple_yet_Effective_Approach_to_Animate_HumanNeRF_with_CVPR_2024_paper.pdf">HumanNeRF-SE: A Simple yet Effective Approach to Animate HumanNeRF with Diverse Poses</a>, 
 		C Ma, YL Liu, Z Wang, W Liu, X Liu, <strong>Z Wang*</strong>, 
 		<em><strong>CVPR</strong></em>, 2024</p>
	<p class="indented"><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Good_Is_Bad_Causality_Inspired_Cloth-Debiasing_for_Cloth-Changing_Person_Re-Identification_CVPR_2023_paper.pdf">Good Is Bad: Causality Inspired Cloth-Debiasing for Cloth-Changing Person Re-Identification</a>, 
 		Z Yang, M Lin, X Zhong, Y Wu, <strong>Z Wang*</strong>, 
 		<em><strong>CVPR</strong></em>, 2023</p>
	<p class="indented"><a href="https://dl.acm.org/doi/10.1145/3581783.3611732">Beyond Domain Gap: Exploiting Subjectivity in Sketch-Based Person Retrieval</a>, 
 		K Lin, Z Wang, <strong>Z Wang*</strong>, Y Zheng, S Satoh, 
 		<em><strong>ACM MM</strong></em>, 2023</p>
	</div>


	<div>
	<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-short" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M4 8a.5.5 0 0 1 .5-.5h5.793L8.146 5.354a.5.5 0 1 1 .708-.708l3 3a.5.5 0 0 1 0 .708l-3 3a.5.5 0 0 1-.708-.708L10.293 8.5H4.5A.5.5 0 0 1 4 8"/>
</svg>Adversarial Attack (AI + Physics)
	<br>
		<a href="https://ieeexplore.ieee.org/document/10602786">Physical Adversarial Attack Meets Computer Vision: A Decade Survey</a>, 
 		Hui Wei, H Tang, X Jia, Z Wang, H Yu, Z Li, S Satoh, LV Gool, <strong>Z Wang*</strong>, 
 		<em><strong>IEEE TPAMI</strong></em>, 2024
	<br>
		<a href="https://nips.cc/virtual/2024/poster/96825">Revisiting Adversarial Patches for Designing Camera-Agnostic Attacks against Person Detection</a>, 
 		H Wei, Z Wang, K Zhang, J Hou, Y Liu, H Tang, <strong>Z Wang*</strong>, 
 		<em><strong>NeurIPS</strong></em>, 2024
	<br>
		<a href="https://dl.acm.org/doi/abs/10.1609/aaai.v37i12.26777">HOTCOLD Block: Fooling Thermal Infrared Detectors with a Novel Wearable Design</a>, 
		 H Wei, Z Wang, X Jia, Y Zheng, H Tang, S Satoh, <strong>Z Wang*</strong>, 
		 <em><strong>AAAI</strong></em>, 2023
	<br>
	</div>

	<div>
	<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-short" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M4 8a.5.5 0 0 1 .5-.5h5.793L8.146 5.354a.5.5 0 1 1 .708-.708l3 3a.5.5 0 0 1 0 .708l-3 3a.5.5 0 0 1-.708-.708L10.293 8.5H4.5A.5.5 0 0 1 4 8"/>
</svg>Hidden Discovery (AI + Social Science)	
	<br>	
 		<a href="https://dl.acm.org/doi/abs/10.1145/3664647.3681113">Predicting the Unseen: A Novel Dataset for Hidden Intention Localization in Pre-abnormal Analysis</a>, 
 		Z Qi, R Zhang, X Hu, W Liu, <strong>Z Wang*</strong>,
 		<em><strong>ACM MM</strong></em>, 2024
	<br>
 		<a href="https://dl.acm.org/doi/10.1145/3581783.3611892">Uncovering the Unseen: Discover Hidden Intentions by Micro-Behavior Graph Reasoning</a>, 
 		Z Zhou, W Liu, D Xu, <strong>Z Wang*</strong>, J Zhao,
 		<em><strong>ACM MM</strong></em>, 2023
	<br>
 		<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548207">Gaze- and Spacing-flow Unveil Intentions: Hidden Follower Discovery</a>, 
 		D Xu, R Hu, <strong>Z Wang</strong>, L Luo, D Li, W Zeng,
 		<em><strong>ACM MM</strong></em>, 2022
	<br>
	</div>	
	
	<br>


	<div class="row">
	<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-lightbulb" viewBox="0 0 16 16">
  <path d="M2 6a6 6 0 1 1 10.174 4.31c-.203.196-.359.4-.453.619l-.762 1.769A.5.5 0 0 1 10.5 13a.5.5 0 0 1 0 1 .5.5 0 0 1 0 1l-.224.447a1 1 0 0 1-.894.553H6.618a1 1 0 0 1-.894-.553L5.5 15a.5.5 0 0 1 0-1 .5.5 0 0 1 0-1 .5.5 0 0 1-.46-.302l-.761-1.77a2 2 0 0 0-.453-.618A5.98 5.98 0 0 1 2 6m6-5a5 5 0 0 0-3.479 8.592c.263.254.514.564.676.941L5.83 12h4.342l.632-1.467c.162-.377.413-.687.676-.941A5 5 0 0 0 8 1"/></svg>
		<h5><strong>Professional Services</strong></h5>
	</div>

	<div>
 		<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-short" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M4 8a.5.5 0 0 1 .5-.5h5.793L8.146 5.354a.5.5 0 1 1 .708-.708l3 3a.5.5 0 0 1 0 .708l-3 3a.5.5 0 0 1-.708-.708L10.293 8.5H4.5A.5.5 0 0 1 4 8"/>
</svg>IEEE Circuits and Systems Society (CAS) Multimedia Systems and Applications Technical Committee (MSA TC) Member 
	</div>
	
	<div>
 		<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-short" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M4 8a.5.5 0 0 1 .5-.5h5.793L8.146 5.354a.5.5 0 1 1 .708-.708l3 3a.5.5 0 0 1 0 .708l-3 3a.5.5 0 0 1-.708-.708L10.293 8.5H4.5A.5.5 0 0 1 4 8"/>
</svg>Associate Editor: 
		<a href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing/editorial-board">IEEE Transactions on Image Processing</a>, 
    <a href="https://www.springer.com/journal/43684/">Autonomous Intelligent Systems</a>, <a href="https://www.springer.com/journal/42979/">SN Computer Science</a>
	</div>
		
	<div>
 		<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-short" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M4 8a.5.5 0 0 1 .5-.5h5.793L8.146 5.354a.5.5 0 1 1 .708-.708l3 3a.5.5 0 0 1 0 .708l-3 3a.5.5 0 0 1-.708-.708L10.293 8.5H4.5A.5.5 0 0 1 4 8"/>
</svg>Guest Editor: 
		<br>
    <a href="https://www.mdpi.com/journal/applsci/">Applied Sciences</a> Special Issue 
    <a href="https://www.mdpi.com/journal/applsci/special_issues/23L188650Q">Recent Advances in Image Processing</a>
		<br>
    <a href="https://www.mdpi.com/journal/electronics">Electronics</a> Special Issue 
    <a href="https://www.mdpi.com/journal/electronics/special_issues/multimedia_AMR">Multimedia Content Analysis, Management and Retrieval: Trends and Challenges</a>
		<br>
    <a href="https://www.journals.elsevier.com/pattern-recognition-letters">Pattern Recognition Letters</a> Special Issue 
    <a href="https://www.journals.elsevier.com/pattern-recognition-letters/call-for-papers/recent-advances-in-deep-learning-model-security">Recent Advances in Deep Learning Model Security</a>
		<br>
    <a href="https://www.mdpi.com/journal/entropy">Entropy</a> Special Issue 
    <a href="https://www.mdpi.com/journal/entropy/special_issues/advances_in_image_fusion">Advances in Image Fusion</a>
		<br>
	</div>

	<div>
 	<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-short" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M4 8a.5.5 0 0 1 .5-.5h5.793L8.146 5.354a.5.5 0 1 1 .708-.708l3 3a.5.5 0 0 1 0 .708l-3 3a.5.5 0 0 1-.708-.708L10.293 8.5H4.5A.5.5 0 0 1 4 8"/>
</svg>Workshops, Tutorials, and Special sessions: 
		<br>
<a href="https://mis-24.github.io/">ACM MM 2024 Workshop on Multi-modal Misinformation Governance in the Era of Foundation Models</a>
		<br>
    <a href="https://skatingverse.github.io/">FG 2024 Workshop & Challenge SkatingVerse</a>
		<br>
    <a href="https://www.zdzheng.xyz/MORE2024/">ICMR 2024 Workshop on Multimedia Object Re-ID: Advancements, Challenges, and Opportunities</a>
		<br>
    <a href="https://anti-uav.github.io/">CVPR 2023 Workshop on The 3rd Anti-UAV Workshop & Challenge</a>
		<br>
    <a href="http://aim-nercms.whu.edu.cn/news/265.html">ICME 2023 Workshop on Seeing Through the Rain (STRAIN): Vision Task Challenges in Real-World Rain Scenes</a>
		<br>
    <a href="https://wangzwhu.github.io/home/acmmm2022_tutorial_mmhe.html">ACM MM 2022 Tutorial on Multimedia Content Understanding in Harsh Environments</a>
		<br>
    <a href="https://www.mipr2021.org/pages/tutorials/#tutorial1">IEEE MIPR 2021 Tutorial on Human-centric Media Understanding: Processing, Generation, Re-identification, and Prediction</a>
		<br>
    <a href="https://wangzwhu.github.io/home/acmmm2020_tutorial_reid.html">ACM MM 2020 Tutorial on Effective and Efficient: Toward Open-world Instance Re-identification</a>
		<br>
    <a href="https://matsui528.github.io/cvpr2020_tutorial_retrieval/">CVPR 2020 Tutorial on Image Retrieval in the Wild</a>
		<br>
    <a href="https://wut-idea.github.io/ICME2021SS.github.io/">IEEE ICME 2021 Special Session on Knowledge-Driven Multi-modal Deep Analysis for Multimedia</a>
		<br>
    <a href="http://mipr.iiitd.edu.in/">IEEE MIPR 2021 Workshop on Cross Modal Person Reidentification</a>
		<br>
    <a href="https://www.wict.pku.edu.cn/huwei/docs/20191028153410897217.html">IEEE ICME 2020 Special Session on Graph Neural Networks for Multimedia Representation Learning</a>
		<br>
    <a href="https://wangzwhu.github.io/home/ICMR20-SS-HCCR.html">ACM ICMR 2020 Special Session on Human-Centric Cross-modal Retrieval</a>
		<br>
	</div>

	<div>
 		<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-short" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M4 8a.5.5 0 0 1 .5-.5h5.793L8.146 5.354a.5.5 0 1 1 .708-.708l3 3a.5.5 0 0 1 0 .708l-3 3a.5.5 0 0 1-.708-.708L10.293 8.5H4.5A.5.5 0 0 1 4 8"/>
</svg>Area Chair: ACM MM 2023/2024, IJCAI 2025, ICME 2020/2021	
	</div>
</div>
	
	<br>
	
	<div class="row">
		<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-award" viewBox="0 0 16 16">
  <path d="M9.669.864 8 0 6.331.864l-1.858.282-.842 1.68-1.337 1.32L2.6 6l-.306 1.854 1.337 1.32.842 1.68 1.858.282L8 12l1.669-.864 1.858-.282.842-1.68 1.337-1.32L13.4 6l.306-1.854-1.337-1.32-.842-1.68zm1.196 1.193.684 1.365 1.086 1.072L12.387 6l.248 1.506-1.086 1.072-.684 1.365-1.51.229L8 10.874l-1.355-.702-1.51-.229-.684-1.365-1.086-1.072L3.614 6l-.25-1.506 1.087-1.072.684-1.365 1.51-.229L8 1.126l1.356.702z"/>
  <path d="M4 11.794V16l4-1 4 1v-4.206l-2.018.306L8 13.126 6.018 12.1z"/></svg>
		<h5><strong>Awards</strong></h5>
	</div>
	<div>
		2023, ACM Wuhan Rising Star Award | ACM武汉新星奖
			<br>
		2020, MEXT Leading Initiative for Excellent Young Researcher (LEADER) | 日本文部科学省卓越研究員
			<br>
		2019, The Best Young Scholar, Association of Chinese Alumni In Japan | 最優秀青年学者者賞（情報通信部門）
			<br>
		2018, CSIG Doctoral Dissertation Nomination Award, China Society of Image and Graphics (CSIG) | 中国图象图形学学会优秀博士学位论文提名奖
			<br>
		2017, ACM Wuhan Doctoral Dissertation Award, Association for Computing Machinery | ACM武汉分会优秀博士论文奖
			<br>
		2014, Best Paper Award, Pacific-Rim Conference on Multimedia (PCM)
			<br>
	</div>	
	
</div>

	    <br>
	    <br>
--------------------------------------------
	    <br>
	    Last modified: Nov. 30, 2024.
	    <br>
Zheng Wang
 	    
	    
</div>	  
<!-- <div class="container" style="max-width: 1600px;"> -->
		
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  </body>
</html>
