<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="assets/css/bootstrap.min.css">
    <title>Zheng Wang's Homepage</title>
  </head>
  

  <body>
    <div class="container" style="max-width: 1600px;">
	

<nav class="navbar navbar-expand-lg navbar-dark bg-primary">
  <a class="navbar-brand" href="index.html">Zheng Wang</a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarColor01" aria-controls="navbarColor01" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="navbarColor01">
    <ul class="navbar-nav mr-auto">
      <li class="nav-item">
        <a class="nav-link" href="member.html">Members</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="publication.html">Publication</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="project.html">Project</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="competition.html">Teaching</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="honor.html">Honor</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="service.html">Service</a>
      </li>
    </ul>
  </div>
</nav>
<br />
<br />
        <div class="row mb-3">
            <div class="col-sm-12">
                <!-- =========== Rich list =========== -->
		    



<h4>Adversarial Attack</h4>
<ul>

	<li class="mb-2">
 		<a href="https://ieeexplore.ieee.org/document/10602786">Physical Adversarial Attack Meets Computer Vision: A Decade Survey</a>, 
 		Hui Wei, H Tang, X Jia, Z Wang, H Yu, Z Li, S Satoh, LV Gool, <strong>Z Wang*</strong>, 
 		<em><strong>IEEE TPAMI</strong></em>, 2024
 	</li>	
	
	<li class="mb-2">
 		<a href="https://nips.cc/virtual/2024/poster/96825">Revisiting Adversarial Patches for Designing Camera-Agnostic Attacks against Person Detection</a>, 
 		H Wei, Z Wang, K Zhang, J Hou, Y Liu, H Tang, <strong>Z Wang*</strong>, 
 		<em><strong>NeurIPS</strong></em>, 2024
 	</li>	
	
	<li class="mb-2">
 		<a href="https://dl.acm.org/doi/10.1145/3581783.3611910">Moir√© Backdoor Attack (MBA): A Novel Trigger for Pedestrian Detectors in the Physical World</a>, 
 		H Wei, H Yu, K Zhang, Z Wang, J Zhu, <strong>Z Wang*</strong>, 
 		<em><strong>ACM MM</strong></em>, 2023
 	</li>	
	
	 <li class="mb-2">
		 <a href="https://dl.acm.org/doi/abs/10.1609/aaai.v37i12.26777">HOTCOLD Block: Fooling Thermal Infrared Detectors with a Novel Wearable Design</a>, 
		 H Wei, Z Wang, X Jia, Y Zheng, H Tang, S Satoh, <strong>Z Wang*</strong>, 
		 <em><strong>AAAI</strong></em>, 2023
	 </li>
</ul>	

<h4>Dataset Refinement</h4>
<ul>
	<li class="mb-2">
 		<a href="">Contributing Dimension Structure of Deep Feature for Coreset Selection</a>, 
 		Z Wan, Z Wang, Y Wang, <strong>Z Wang*</strong>, H Zhu, S Satoh,
 		<em><strong>AAAI</strong></em>, 2024
 	</li>	
	
	 <li class="mb-2">
		 <a href="https://dl.acm.org/doi/10.1145/3627157">A Survey of Dataset Refinement for Problems in Computer Vision Datasets</a>, 
		 Z Wan, Z Wang, C Chung, <strong>Z Wang*</strong>, 
		 <em><strong>ACM Computing Surveys</strong></em>, 2023
	 </li>	
 	<li class="mb-2">
 		<a href="https://doi.org/10.1002/int.22829">Efficient Virtual Data Search for Annotation-free Vehicle Re-identification</a>, 
 		Z Wan, X Xu, <strong>Z Wang</strong>, T Yamasaki, X Zhang, R Hu,
 		<em><strong>International Journal of Intelligent Systems</strong></em>, 2022
 		<a href="https://onlinelibrary.wiley.com/toc/1098111x/2022/37/5" class="badge badge-pill badge-danger">Cover Paper</a>
 	</li>	
</ul>	


<h4>Multimedia Enhancement (Video Super-resolution, Image Enhancement)</h4>
<ul>
 	<li class="mb-2">
 		<a href="">IQ-VFI: Implicit Quadratic Motion Estimation for Video Frame Interpolation</a>, 
 		M Hu, K Jiang, Z Zhong, <strong>Z Wang*</strong>, Y Zheng, 
 		<em><strong>CVPR</strong></em>, 2024
 	</li>
 	<li class="mb-2">
 		<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Spatial-Temporal_Space_Hand-in-Hand_Spatial-Temporal_Video_Super-Resolution_via_Cycle-Projected_Mutual_Learning_CVPR_2022_paper.pdf">Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution via Cycle-Projected Mutual Learning</a>, 
 		M Hu, K Jiang, L Liao, J Xiao, J Jiang, <strong>Z Wang*</strong>, 
 		<em><strong>CVPR</strong></em>, 2022
 	</li>
 	<li class="mb-2">
 		<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547874">You Only Align Once: Bidirectional Interaction for Spatial-Temporal Video Super-Resolution</a>, 
 		M Hu, K Jiang, Z Nie, <strong>Z Wang*</strong>, 
 		<em><strong>ACM MM</strong></em>, 2022
 	</li>
 	<li class="mb-2">
 		<a href="https://dl.acm.org/doi/10.1145/3503161.3547875">Progressive Spatial-temporal Collaborative Network for Video Frame Interpolation</a>, 
 		M Hu, K Jiang, L Liao, Z Nie, J Xiao, <strong>Z Wang*</strong>, 
 		<em><strong>ACM MM</strong></em>, 2022
 	</li>
	<li class="mb-2">
 		<a href="https://ojs.aaai.org/index.php/AAAI/article/view/25165">Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-Resolution</a>, 
 		M Hu, K Jiang, Z Nie, J Zhou, <strong>Z Wang*</strong>, 
 		<em><strong>AAAI</strong></em>, 2023
 	</li>
	<li class="mb-2">
 		<a href="https://ieeexplore.ieee.org/abstract/document/10177211">CycMuNet+: Cycle-Projected Mutual Learning for Spatial-Temporal Video Super-Resolution</a>, 
		M Hu, K Jiang, <strong>Z Wang*</strong>, X Bai, R Hu,
 		<em><strong>IEEE TPAMI</strong></em>, 2023
 	</li>	
	<li class="mb-2">
 		<a href="">Multi-Scale Fusion and Decomposition Network for Single Image Deraining</a>, 
 		Q Wang, K Jiang, <strong>Z Wang*</strong>, W Ren, J Zhang, CW Lin, 
 		<em><strong>IEEE TIP</strong></em>, 2023
 	</li>	
	<li class="mb-2">
 		<a href="https://ieeexplore.ieee.org/document/9515582">Rain-Free and Residue Hand-in-Hand: A Progressive Coupled Network for Real-Time Image Deraining</a>, 
 		K Jiang, Z Wang, P Yi, C Chen, <strong>Z Wang</strong>, X Wang, J Jiang, CW Lin,
 		<em><strong>IEEE TIP</strong></em>, 2021
<!--  		<a href="https://github.com/kuijiang0802/PCNet" class="badge badge-pill badge-info">code</a>  -->
 	</li>

</ul>	


		    
		    
<h4>Human-Centric Multimedia (Person Re-identification, Human Behavior Analysis)</h4>
<ul>
	<li class="mb-2">
 		<a href="">HumanNeRF-SE: A Simple yet Effective Approach to Animate HumanNeRF with Diverse Poses</a>, 
 		C Ma, YL Liu, Z Wang, W Liu, X Liu, <strong>Z Wang*</strong>, 
 		<em><strong>CVPR</strong></em>, 2024
 	</li>
	<li class="mb-2">
 		<a href="">Bi-Causal: Group Activity Recognition via Bidirectional Causality</a>, 
 		Y Zhang, W Liu, D Xu, Z Zhou, <strong>Z Wang*</strong>, 
 		<em><strong>CVPR</strong></em>, 2024
 	</li>
	
	<li class="mb-2">
 		<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Good_Is_Bad_Causality_Inspired_Cloth-Debiasing_for_Cloth-Changing_Person_Re-Identification_CVPR_2023_paper.pdf">Good Is Bad: Causality Inspired Cloth-Debiasing for Cloth-Changing Person Re-Identification</a>, 
 		Z Yang, M Lin, X Zhong, Y Wu, <strong>Z Wang*</strong>, 
 		<em><strong>CVPR</strong></em>, 2023
 	</li>
 	<li class="mb-2">
 		<a href="https://wangzwhu.github.io/home/0158.pdf">Learning to Reduce Dual-level Discrepancy for Infrared-Visible Person Re-identification</a>,  					
 		Z Wang, <strong>Z Wang*</strong>, Y Zheng, YY Chuang, S Satoh, 
 		<em><strong>CVPR</strong></em>, 2019
 	</li>	
	<li class="mb-2">
		<a href="https://dl.acm.org/doi/10.1145/3581783.3611732">Beyond Domain Gap: Exploiting Subjectivity in Sketch-Based Person Retrieval</a>, 
 		K Lin, Z Wang, <strong>Z Wang*</strong>, Y Zheng, S Satoh, 
 		<em><strong>ACM MM</strong></em>, 2023
 	</li>	
	<li class="mb-2">
 		<a href="https://dl.acm.org/doi/10.1145/3581783.3611892">Uncovering the Unseen: Discover Hidden Intentions by Micro-Behavior Graph Reasoning</a>, 
 		Z Zhou, W Liu, D Xu, <strong>Z Wang*</strong>, J Zhao,
 		<em><strong>ACM MM</strong></em>, 2023
 	</li>	
	<li class="mb-2">
 		<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548207">Gaze- and Spacing-flow Unveil Intentions: Hidden Follower Discovery</a>, 
 		D Xu, R Hu, <strong>Z Wang</strong>, L Luo, D Li, W Zeng,
 		<em><strong>ACM MM</strong></em>, 2022
 	</li>
	<li class="mb-2">
 		<a href="https://dl.acm.org/doi/10.1145/3474085.3475664">Trajectory is not Enough: Hidden Following Detection</a>, 
 		D Xu, R Hu, Z Xiong, <strong>Z Wang</strong>, L Luo, D Li, 
 		<em><strong>ACM MM</strong></em>, 2021
 	</li>
 
	 <li class="mb-2">
 		<a href="https://dl.acm.org/citation.cfm?id=3351027">DoT-GNN: Domain-Transferred Graph Neural Network for Group Re-identification</a>, 					
 		Z Huang, <strong>Z Wang*</strong>, W Hu, CW Lin, S Satoh, 
 		<em><strong>ACM MM</strong></em>, 2019
 	</li>	

	<li class="mb-2">
 		<a href="https://aaai-2022.virtualchair.net/poster_aaai292">ELMA: Energy-based Learning for Multi-Agent Activity Forecasting</a>, 
 		Y Li, P Wang, L Chen, <strong>Z Wang*</strong>, CY Chan, 
 		<em><strong>AAAI</strong></em>, 2022
 	</li>
 	<li class="mb-2">
		 <a href="https://wangzwhu.github.io/home/AAAI20_cross_diffusion.pdf">Mining on Heterogeneous Manifolds for Zero-shot Cross-modal Image Retrieval</a>,  
		 F Yang, <strong>Z Wang*</strong>, J Xiao, S Satoh,  
		 <em><strong>AAAI</strong></em>, 2020
<!-- 		 <a href="https://github.com/fyang93/cross-modal-retrieval" class="badge badge-pill badge-info">code</a> -->
 	</li>

	<li class="mb-2">
 		<a href="https://www.ijcai.org/proceedings/2018/0541.pdf">Cascaded SR-GAN for Scale-Adaptive Low Resolution Person Re-identification</a>,  						
 		<strong>Z Wang</strong>, M Ye, F Yang, X Bai, S Satoh,  
 		<em><strong>IJCAI</strong></em>, 2018
<!--  		<a href="https://github.com/wangzwhu/CSR-GAN" class="badge badge-pill badge-info">code</a> -->
 	</li>	
        <li class="mb-2">
 		<a href="https://www.ijcai.org/Proceedings/16/Papers/379.pdf">Scale-adaptive Low-resolution Person Re-identification via Learning A Discriminating Surface</a>, 					
 		<strong>Z Wang</strong>, R Hu, Y Yu, J Jiang, C Liang, J Wang, 
 		<em><strong>IJCAI</strong></em>, 2016
 	</li>	
	 <li class="mb-2">
		 <a href="https://ieeexplore.ieee.org/document/9428200">Unsupervised Video Person Re-identification via Noise and Hard Frame Aware Clustering</a>, 
		 P Xie, X Xu, <strong>Z Wang</strong>, T Yamasaki, 
		 <em><strong>ICME</strong></em>, 2021
		 <span class="badge badge-pill badge-danger">Best Paper Candidate</span>
	 </li>
	<li class="mb-2">
 		<a href="https://link.springer.com/chapter/10.1007/978-3-319-13168-9_1">Region-based Interactive Ranking Optimization For Person Re-identification</a>, 					
 		<strong>Z Wang</strong>, R Hu, C Liang, Q Leng, K Sun, 
 		<em><strong>PCM</strong></em>, 2014
<!--  		<a href="http://v.youku.com/v_show/id_XMTc1NjQyMDYxNg==.html" class="badge badge-pill badge-success">video</a> -->
 		<span class="badge badge-pill badge-danger">Best Paper Award</span>
 	</li>
</ul> 
</ul>

<h4>Multimedia Understanding</h4>
<ul>
	 <li class="mb-2">
 		<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Both_Style_and_Fog_Matter_Cumulative_Domain_Adaptation_for_Semantic_CVPR_2022_paper.pdf">Both Style and Fog Matter: Cumulative Domain Adaptation for Semantic Foggy Scene Understanding</a>, 
 		X Ma, Z Wang, Y Zhan, Y Zheng, <strong>Z Wang*</strong>, D Dai, CW Lin,
 		<em><strong>CVPR</strong></em>, 2022
 		<a href="https://acdc.vision.ee.ethz.ch/benchmarks#semanticSegmentation" class="badge badge-pill badge-danger">Top Performance in ACDC-fog Benchmark</a>
 	</li>
	<li class="mb-2">
 		<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Scratch_Each_Others_Back_Incomplete_Multi-Modal_Brain_Tumor_Segmentation_via_ICCV_2023_paper.pdf">Scratch Each Other‚Äôs Back: Incomplete Multi-modal Brain Tumor Segmentation Via Category Aware Group Self-Support Learning</a>, 
 		Y Qiu, D Chen, H Yao, Y Xu, <strong>Z Wang*</strong>, 
 		<em><strong>ICCV</strong></em>, 2023
 	</li>
	<li class="mb-2">
 		<a href="https://dl.acm.org/doi/10.1145/3581783.3611797">Striking a Balance: Unsupervised Cross-Domain Crowd Counting via Knowledge Diffusion</a>, 
 		H Xie, Z Yang, H Zhu, <strong>Z Wang*</strong>, 
 		<em><strong>ACM MM</strong></em>, 2023
 	</li>		

	<li class="mb-2">
		 <a href="https://dl.acm.org/doi/10.1145/3394171.3413825">Towards Unsupervised Crowd Counting via Regression-Detection Bi-knowledge Transfer</a>, 
		 Y Liu, <strong>Z Wang*</strong>, M Shi, S Satoh, Q Zhao, H Yang,  
		 <em><strong>ACM MM</strong></em>, 2020
 	</li>
	
            </div>
        </div>



    </div>


    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  </body>
</html>



